{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NCR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W16NrwageWrG",
        "outputId": "2d330d43-11fd-4110-ce56-14ced3e6bb46"
      },
      "source": [
        "!pip install tensorflow==1.14\n",
        "!pip install keras==2.2.4\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd gdrive/My Drive/CS6101/NCR"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/28/96efba1a516cdacc2e2d6d081f699c001d414cc8ca3250e6d59ae657eb2b/tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3MB 84kB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.3.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.12.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.36.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (3.12.4)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 43.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.32.0)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 24.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.14) (54.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.7.4.3)\n",
            "Installing collected packages: keras-applications, tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n",
            "Collecting keras==2.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.1.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (2.10.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.15.0)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-2.2.4\n",
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/CS6101/NCR\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEulQ49keXs1",
        "outputId": "2db720bd-bd59-4cca-f58b-3e8437187a28"
      },
      "source": [
        "from time import time\n",
        "import numpy as np\n",
        "import argparse\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras.regularizers import l1,l2\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Embedding,Input,Dense,merge,Flatten,Lambda,Multiply,concatenate,Add\n",
        "from keras.optimizers import Adam,Adagrad,SGD,RMSprop,Adadelta\n",
        "from keras.initializers import RandomNormal,TruncatedNormal"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nZ3784RekQD"
      },
      "source": [
        "import math\n",
        "import multiprocessing\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Global variables that are shared across processes\n",
        "_model = None\n",
        "_testRatings = None\n",
        "_testNegatives = None\n",
        "_K = None\n",
        "\n",
        "\n",
        "def evaluate_model(model, testRatings, testNegatives, K, num_thread):\n",
        "    \"\"\"\n",
        "    Evaluate the performance (Hit_Ratio, NDCG) of top-K recommendation\n",
        "    Return: score of each test rating.\n",
        "    \"\"\"\n",
        "    global _model\n",
        "    global _testRatings\n",
        "    global _testNegatives\n",
        "    global _K\n",
        "    _model = model\n",
        "    _testRatings = testRatings\n",
        "    _testNegatives = testNegatives\n",
        "    _K = K\n",
        "\n",
        "    hits, ndcgs = [], []\n",
        "    if (num_thread > 1):  # Multi-thread\n",
        "        pool = multiprocessing.Pool(processes=num_thread)\n",
        "        res = pool.map(eval_one_rating, range(len(_testRatings)))\n",
        "        pool.close()\n",
        "        pool.join()\n",
        "        hits = [r[0] for r in res]\n",
        "        ndcgs = [r[1] for r in res]\n",
        "        return (hits, ndcgs)\n",
        "    # Single thread\n",
        "\n",
        "    for idx in range(len(_testRatings)):\n",
        "        (hr, ndcg) = eval_one_rating(idx)\n",
        "        hits.append(hr)\n",
        "        ndcgs.append(ndcg)\n",
        "    return (hits, ndcgs)\n",
        "\n",
        "\n",
        "def eval_one_rating(idx):\n",
        "    rating = _testRatings[idx]\n",
        "    items = _testNegatives[idx]\n",
        "    u = rating[0]\n",
        "    gtItem = rating[1]\n",
        "    if gtItem==-1:\n",
        "        return -1,-1\n",
        "    # items.append(gtItem)\n",
        "    # Get prediction scores\n",
        "\n",
        "    users = np.full(len(items), u, dtype='int32')\n",
        "    item_pos=np.full(len(items),gtItem,dtype='int32')\n",
        "\n",
        "    predictions1 = _model.predict([users,item_pos,np.array(items)],batch_size=101, verbose=0)\n",
        "    predictions2 = _model.predict([users,np.array(items),item_pos], batch_size=101, verbose=0)\n",
        "    prediction=predictions1-predictions2\n",
        "\n",
        "    num_err=len(prediction[prediction<0])\n",
        "    if num_err>=_K:\n",
        "        hr=0\n",
        "        ndcg=0\n",
        "    else:\n",
        "        hr=1\n",
        "        ndcg=math.log(2) / math.log(num_err + 2)\n",
        "\n",
        "    return (hr, ndcg)\n",
        "\n",
        "def evaluate_aux_model(model, testRatings, testNegatives, K, num_thread):\n",
        "    \"\"\"\n",
        "    Evaluate the performance (Hit_Ratio, NDCG) of top-K recommendation\n",
        "    Return: score of each test rating.\n",
        "    \"\"\"\n",
        "    global _model\n",
        "    global _testRatings\n",
        "    global _testNegatives\n",
        "    global _K\n",
        "    _model = model\n",
        "    _testRatings = testRatings\n",
        "    _testNegatives = testNegatives\n",
        "    _K = K\n",
        "\n",
        "    hits, ndcgs = [], []\n",
        "    if (num_thread > 1):  # Multi-thread\n",
        "        pool = multiprocessing.Pool(processes=num_thread)\n",
        "        res = pool.map(eval_one_aux_rating, range(len(_testRatings)))\n",
        "        pool.close()\n",
        "        pool.join()\n",
        "        hits = [r[0] for r in res]\n",
        "        ndcgs = [r[1] for r in res]\n",
        "        return (hits, ndcgs)\n",
        "    # Single thread\n",
        "\n",
        "    for idx in range(len(_testRatings)):\n",
        "        (hr, ndcg) = eval_one_aux_rating(idx)\n",
        "        hits.append(hr)\n",
        "        ndcgs.append(ndcg)\n",
        "    return (hits, ndcgs)\n",
        "\n",
        "\n",
        "def eval_one_aux_rating(idx):\n",
        "    rating = _testRatings[idx]\n",
        "    items = _testNegatives[idx]\n",
        "    u = rating[0]\n",
        "    aux = rating[2]\n",
        "    gtItem = rating[1]\n",
        "    if gtItem==-1:\n",
        "        return -1,-1\n",
        "    # items.append(gtItem)\n",
        "    # Get prediction scores\n",
        "\n",
        "    users = np.full(len(items), u, dtype='int32')\n",
        "    item_pos=np.full(len(items),gtItem,dtype='int32')\n",
        "    aux=np.full(len(items), aux, dtype='int32')\n",
        "\n",
        "    predictions1 = _model.predict([users,item_pos,np.array(items),aux],batch_size=101, verbose=0)\n",
        "    predictions2 = _model.predict([users,np.array(items),item_pos,aux], batch_size=101, verbose=0)\n",
        "    prediction=predictions1-predictions2\n",
        "\n",
        "    num_err=len(prediction[prediction<0])\n",
        "    if num_err>=_K:\n",
        "        hr=0\n",
        "        ndcg=0\n",
        "    else:\n",
        "        hr=1\n",
        "        ndcg=math.log(2) / math.log(num_err + 2)\n",
        "\n",
        "    return (hr, ndcg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dbk-eHA7-mW0"
      },
      "source": [
        "def evaluate_feature_model(model, testRatings, testNegatives, K, num_thread):\n",
        "    \"\"\"\n",
        "    Evaluate the performance (Hit_Ratio, NDCG) of top-K recommendation\n",
        "    Return: score of each test rating.\n",
        "    \"\"\"\n",
        "    global _model\n",
        "    global _testRatings\n",
        "    global _testNegatives\n",
        "    global _K\n",
        "    _model = model\n",
        "    _testRatings = testRatings\n",
        "    _testNegatives = testNegatives\n",
        "    _K = K\n",
        "\n",
        "    hits, ndcgs = [], []\n",
        "    if (num_thread > 1):  # Multi-thread\n",
        "        pool = multiprocessing.Pool(processes=num_thread)\n",
        "        res = pool.map(eval_one_feature_rating, range(len(_testRatings)))\n",
        "        pool.close()\n",
        "        pool.join()\n",
        "        hits = [r[0] for r in res]\n",
        "        ndcgs = [r[1] for r in res]\n",
        "        return (hits, ndcgs)\n",
        "    # Single thread\n",
        "\n",
        "    for idx in range(len(_testRatings)):\n",
        "        (hr, ndcg) = eval_one_feature_rating(idx)\n",
        "        hits.append(hr)\n",
        "        ndcgs.append(ndcg)\n",
        "    return (hits, ndcgs)\n",
        "\n",
        "\n",
        "def eval_one_feature_rating(idx):\n",
        "    rating = _testRatings[idx]\n",
        "    items = _testNegatives[idx]\n",
        "    u = rating[0]\n",
        "    gender = rating[3]\n",
        "    age = rating[4]\n",
        "    occupation = rating[5]\n",
        "    gtItem = rating[1]\n",
        "    if gtItem==-1:\n",
        "        return -1,-1\n",
        "    # items.append(gtItem)\n",
        "    # Get prediction scores\n",
        "\n",
        "    users = np.full(len(items), u, dtype='int32')\n",
        "    item_pos=np.full(len(items),gtItem,dtype='int32')\n",
        "    age=np.full(len(items), age, dtype='int32')\n",
        "    gender=np.full(len(items), gender, dtype='int32')\n",
        "    occupation=np.full(len(items), occupation, dtype='int32')\n",
        "\n",
        "    predictions1 = _model.predict([users,item_pos,np.array(items),gender,age,occupation],batch_size=101, verbose=0)\n",
        "    predictions2 = _model.predict([users,np.array(items),item_pos,gender,age,occupation], batch_size=101, verbose=0)\n",
        "    prediction=predictions1-predictions2\n",
        "\n",
        "    num_err=len(prediction[prediction<0])\n",
        "    if num_err>=_K:\n",
        "        hr=0\n",
        "        ndcg=0\n",
        "    else:\n",
        "        hr=1\n",
        "        ndcg=math.log(2) / math.log(num_err + 2)\n",
        "\n",
        "    return (hr, ndcg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YacCwY3eeodf"
      },
      "source": [
        "import scipy.sparse as sp\n",
        "import numpy as np\n",
        "\n",
        "class DataSet:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.pos_per_user = None\n",
        "        self.nUsers = 0\n",
        "        self.nItems = 0\n",
        "        self.nClicks = 0\n",
        "\n",
        "        self.userids = {}\n",
        "        self.itemids = {}\n",
        "\n",
        "        self.rUserids = {}\n",
        "        self.rItemids={}\n",
        "\n",
        "        self.pos_per_user={}\n",
        "\n",
        "    # def loadData(self, filepath, userMin, itemMin):\n",
        "\n",
        "    def loadClicks(self, filepath, userMin, itemMin):\n",
        "\n",
        "        uCounts={}\n",
        "        iCounts={}\n",
        "        nRead=0\n",
        "        print(\"  Loading clicks from %s, userMin = %d  itemMin = %d \", filepath, userMin, itemMin)\n",
        "\n",
        "        with open(filepath, 'r') as f:\n",
        "            for line in f.readlines():\n",
        "                uName, iName, rating, time= line.strip().split(' ')\n",
        "                nRead+=1\n",
        "                if uName not in uCounts:\n",
        "                    uCounts[uName]=0\n",
        "                if iName not in iCounts:\n",
        "                    iCounts[iName]=0\n",
        "\n",
        "                uCounts[uName]+=1\n",
        "                iCounts[iName]+=1\n",
        "        print(\"\\n  First pass: #users = %d, #items = %d, #clicks = %d\\n\",\n",
        "        len(uCounts),len(iCounts), nRead)\n",
        "\n",
        "\n",
        "\n",
        "        with open(filepath, 'r') as f:\n",
        "            for line in f.readlines():\n",
        "                uName, iName, rating, time= line.strip().split(' ')\n",
        "                try:\n",
        "                    tmp = int(time)\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "                if uCounts[uName]< userMin:\n",
        "                    continue\n",
        "\n",
        "                if iCounts[iName]< itemMin:\n",
        "                    continue\n",
        "\n",
        "                self.nClicks+=1\n",
        "\n",
        "                if  iName not in self.itemids:\n",
        "                    self.rItemids[self.nItems]=iName\n",
        "                    self.itemids[iName]=self.nItems\n",
        "                    self.nItems+=1\n",
        "\n",
        "                if uName not in self.userids:\n",
        "                    self.rUserids[self.nUsers]=uName\n",
        "                    self.userids[uName]=self.nUsers\n",
        "                    # rUserids maps int userid (start 0) to string userid (start 1)\n",
        "                    # userids maps string userid(start 1) to int userid (start 0)\n",
        "                    self.nUsers+=1\n",
        "                    self.pos_per_user[self.userids[uName]]=[]\n",
        "                self.pos_per_user[self.userids[uName]].append((self.itemids[iName], int(time)))\n",
        "\n",
        "            print(\"  Sorting clicks for each users \")\n",
        "\n",
        "            for u in range(self.nUsers):\n",
        "                sorted(self.pos_per_user[u], key=lambda d: d[1])\n",
        "            print(\"\\n \\\"nUsers\\\": %d,\\\"nItems\\\":%d, \\\"nClicks\\\":%d\\n\",self.nUsers,self.nItems,self.nClicks)\n",
        "\n",
        "            self.val_per_user = []\n",
        "            self.test_per_user = []\n",
        "            self.train_per_user={}\n",
        "            self.test_negative_per_user = {}\n",
        "            mat = sp.dok_matrix((self.nUsers, self.nItems), dtype=np.float32)\n",
        "            np.random.seed(2017)\n",
        "            for u in range(self.nUsers):\n",
        "\n",
        "                if len(self.pos_per_user[u])<3:\n",
        "                    item_test=-1\n",
        "                    item_valid=-1\n",
        "                    continue\n",
        "\n",
        "                item_test=self.pos_per_user[u][-1][0]\n",
        "                self.pos_per_user[u].pop()\n",
        "                item_valid=self.pos_per_user[u][-1][0]\n",
        "                self.pos_per_user[u].pop()\n",
        "\n",
        "                # item_val=self.pos_per_user[u][-1][0]\n",
        "                # self.pos_per_user[u].pop()\n",
        "                # self.train_per_user[u]=[]\n",
        "                self.train_per_user[u]=[e[0] for e in self.pos_per_user[u]]\n",
        "                row = user_df[user_df.id==self.rUserids[u]].iloc[0]\n",
        "                self.test_per_user.append([u,item_test,row['aux_info'],gender2id[row['gender']],age2id[row['age_group']],occupation2id[row['occupation']]])\n",
        "                # self.test_per_user[u]=item_test\n",
        "                self.val_per_user.append([u,item_valid,row['aux_info'],gender2id[row['gender']],age2id[row['age_group']],occupation2id[row['occupation']]])\n",
        "\n",
        "                for item in self.train_per_user[u]:\n",
        "                    mat[u,item]=1.0\n",
        "\n",
        "                self.test_negative_per_user[u]=[]\n",
        "                for i in range(100):\n",
        "                    neg_item_id = np.random.randint(0,self.nItems)\n",
        "                    while neg_item_id in self.train_per_user[u] or neg_item_id==item_test \\\n",
        "                          or neg_item_id==item_valid or neg_item_id in self.test_negative_per_user[u]:\n",
        "                        neg_item_id = np.random.randint(0, self.nItems)\n",
        "                    self.test_negative_per_user[u].append(neg_item_id)\n",
        "            self.trainMatrix = mat\n",
        "            self.testRatings = self.test_per_user\n",
        "            self.validRatings = self.val_per_user\n",
        "\n",
        "            self.testNegatives=[]\n",
        "            for u in range(self.nUsers):\n",
        "                if u in self.train_per_user:\n",
        "                    self.testNegatives.append([e for e in self.test_negative_per_user[u]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4M4S_BHBeq2O"
      },
      "source": [
        "def get_model(num_users,num_items,mf_dim=10,layers=[10],reg_layers=[0,0,0,0],reg_mf=0):\n",
        "    num_layer=len(layers)\n",
        "\n",
        "    user_input=Input(shape=(1,),dtype='int32')\n",
        "    item_input_pos=Input(shape=(1,),dtype='int32')\n",
        "    item_input_neg = Input(shape=(1,), dtype='int32')\n",
        "\n",
        "    MF_embedding_user=Embedding(input_dim=num_users,output_dim=mf_dim,embeddings_initializer='random_normal',\n",
        "                                name='mf_user_embedding',embeddings_regularizer=l2(reg_mf),input_length=1)\n",
        "    MF_embedding_item = Embedding(input_dim=num_items, output_dim=mf_dim, embeddings_initializer='random_normal',\n",
        "                                  name='mf_item_embedding',embeddings_regularizer=l2(reg_mf), input_length=1)\n",
        "    MLP_embedding_user=Embedding(input_dim=num_users,output_dim=layers[0],embeddings_initializer='random_normal',\n",
        "                                 name='mlp_user_embedding', embeddings_regularizer=l2(reg_mf),input_length=1)\n",
        "    MLP_embedding_item = Embedding(input_dim=num_items, output_dim=layers[0], embeddings_initializer='random_normal',\n",
        "                                   name='mlp_item_embedding',embeddings_regularizer=l2(reg_mf), input_length=1)\n",
        "\n",
        "    mf_user_latent=Flatten()(MF_embedding_user(user_input))\n",
        "    mf_item_latent_pos=Flatten()(MF_embedding_item(item_input_pos))\n",
        "    mf_item_latent_neg = Flatten()(MF_embedding_item(item_input_neg))\n",
        "\n",
        "\n",
        "    prefer_pos = Multiply()([mf_user_latent, mf_item_latent_pos])\n",
        "    prefer_neg = Multiply()([mf_user_latent, mf_item_latent_neg])\n",
        "    prefer_neg = Lambda(lambda x: x)(prefer_neg)\n",
        "    mf_vector = concatenate([prefer_pos, prefer_neg])\n",
        "\n",
        "\n",
        "    mlp_user_latent=Flatten()(MLP_embedding_user(user_input))\n",
        "    mlp_item_latent_pos=Flatten()(MLP_embedding_item(item_input_pos))\n",
        "    mlp_item_latent_neg=Flatten()(MLP_embedding_item(item_input_neg))\n",
        "    mlp_item_latent_neg=Lambda(lambda x: x)(mlp_item_latent_neg)\n",
        "    mlp_vector=concatenate([mlp_user_latent,mlp_item_latent_pos,mlp_item_latent_neg])\n",
        "    for idx in range(1,num_layer):\n",
        "        layer=Dense(layers[idx],kernel_regularizer=l2(0.0000),activation='tanh',name=\"layer%d\" %idx)\n",
        "        mlp_vector=layer(mlp_vector)\n",
        "\n",
        "    predict_vector=concatenate([mf_vector,mlp_vector])\n",
        "\n",
        "    prediction=Dense(1,activation='sigmoid',kernel_initializer='lecun_uniform',name='prediction')(predict_vector)\n",
        "    model=Model(inputs=[user_input,item_input_pos,item_input_neg],outputs=prediction)\n",
        "\n",
        "    tf.keras.utils.plot_model(\n",
        "      model,\n",
        "      to_file=\"model.png\",\n",
        "      show_layer_names=True,\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "def get_train_instances(train, num_negatives):\n",
        "    user_input,item_pos,item_neg,labels = [],[],[],[]\n",
        "    num_items= train.shape[1]\n",
        "    for (u, i) in train.keys():\n",
        "        # positive instance\n",
        "        user_input.append(u)\n",
        "        item_pos.append(i)\n",
        "        j = np.random.randint(num_items)\n",
        "        while (u, j) in train.keys():\n",
        "            j = np.random.randint(num_items)\n",
        "        item_neg.append(j)\n",
        "        labels.append(1)\n",
        "\n",
        "        user_input.append(u)\n",
        "        item_pos.append(j)\n",
        "        item_neg.append(i)\n",
        "        labels.append(0)\n",
        "\n",
        "        # negative instances\n",
        "\n",
        "        for cnt in range(num_negatives-1):\n",
        "            user_input.append(u)\n",
        "            j=np.random.randint(num_items)\n",
        "            while (u,j) in train.keys():\n",
        "                j = np.random.randint(num_items)\n",
        "            item_pos.append(j)\n",
        "            item_neg.append(i)\n",
        "            labels.append(0)\n",
        "\n",
        "    # np.random.seed(123)\n",
        "    # np.random.shuffle(user_input)\n",
        "    # np.random.seed(123)\n",
        "    # np.random.shuffle(item_pos)\n",
        "    # np.random.seed(123)\n",
        "    # np.random.shuffle(item_neg)\n",
        "    # np.random.seed(123)\n",
        "    # np.random.shuffle(labels)\n",
        "    return user_input, item_pos,item_neg,labels\n",
        "\n",
        "def get_feature_model(num_users,num_items,gender_inp,age_inp,occupation_inp,mf_dim=10,layers=[10],reg_layers=[0,0,0,0],reg_mf=0):\n",
        "    num_layer=len(layers)\n",
        "\n",
        "    user_input=Input(shape=(1,),dtype='int32',name=\"userid_input\")\n",
        "    item_input_pos=Input(shape=(1,),dtype='int32',name=\"pos_item_input\")\n",
        "    item_input_neg = Input(shape=(1,), dtype='int32',name=\"neg_item_input\")\n",
        "    gender_input=Input(shape=(1,),dtype='int32',name=\"gender_input\")\n",
        "    age_input=Input(shape=(1,),dtype='int32',name=\"age_input\")\n",
        "    occupation_input=Input(shape=(1,),dtype='int32',name=\"occupation_input\")\n",
        "\n",
        "    MF_embedding_user=Embedding(input_dim=num_users,output_dim=int(mf_dim),embeddings_initializer='random_normal',\n",
        "                                name='mf_user_embedding',embeddings_regularizer=l2(reg_mf),input_length=1)\n",
        "    MF_embedding_gender=Embedding(input_dim=gender_inp,output_dim=int(mf_dim),embeddings_initializer='random_normal',\n",
        "                                    name='gender_embedding',embeddings_regularizer=l2(reg_mf),input_length=1)\n",
        "    MF_embedding_age=Embedding(input_dim=age_inp,output_dim=int(mf_dim),embeddings_initializer='random_normal',\n",
        "                                    name='age_embedding',embeddings_regularizer=l2(reg_mf),input_length=1)\n",
        "    MF_embedding_occupation=Embedding(input_dim=occupation_inp,output_dim=int(mf_dim),embeddings_initializer='random_normal',\n",
        "                                    name='occupation_embedding',embeddings_regularizer=l2(reg_mf),input_length=1)\n",
        "    MF_embedding_item = Embedding(input_dim=num_items, output_dim=mf_dim, embeddings_initializer='random_normal',\n",
        "                                  name='mf_item_embedding',embeddings_regularizer=l2(reg_mf), input_length=1)\n",
        "    MLP_embedding_user=Embedding(input_dim=num_users,output_dim=layers[0],embeddings_initializer='random_normal',\n",
        "                                 name='mlp_user_embedding', embeddings_regularizer=l2(reg_mf),input_length=1)\n",
        "    MLP_embedding_item = Embedding(input_dim=num_items, output_dim=layers[0], embeddings_initializer='random_normal',\n",
        "                                   name='mlp_item_embedding',embeddings_regularizer=l2(reg_mf), input_length=1)\n",
        "\n",
        "    mf_user_latent=Add()([Flatten()(MF_embedding_user(user_input)), Flatten()(MF_embedding_gender(gender_input)), Flatten()(MF_embedding_age(age_input)), Flatten()(MF_embedding_occupation(occupation_input))])\n",
        "    mf_item_latent_pos=Flatten()(MF_embedding_item(item_input_pos))\n",
        "    mf_item_latent_neg = Flatten()(MF_embedding_item(item_input_neg))\n",
        "\n",
        "\n",
        "    prefer_pos = Multiply()([mf_user_latent, mf_item_latent_pos])\n",
        "    prefer_neg = Multiply()([mf_user_latent, mf_item_latent_neg])\n",
        "    prefer_neg = Lambda(lambda x: x)(prefer_neg)\n",
        "    mf_vector = concatenate([prefer_pos, prefer_neg])\n",
        "\n",
        "\n",
        "    mlp_user_latent=Add()([Flatten()(MF_embedding_user(user_input)), Flatten()(MF_embedding_gender(gender_input)), Flatten()(MF_embedding_age(age_input)), Flatten()(MF_embedding_occupation(occupation_input))])\n",
        "    mlp_item_latent_pos=Flatten()(MLP_embedding_item(item_input_pos))\n",
        "    mlp_item_latent_neg=Flatten()(MLP_embedding_item(item_input_neg))\n",
        "    mlp_item_latent_neg=Lambda(lambda x: x)(mlp_item_latent_neg)\n",
        "    mlp_vector=concatenate([mlp_user_latent,mlp_item_latent_pos,mlp_item_latent_neg])\n",
        "    for idx in range(1,num_layer):\n",
        "        layer=Dense(layers[idx],kernel_regularizer=l2(0.0000),activation='tanh',name=\"layer%d\" %idx)\n",
        "        mlp_vector=layer(mlp_vector)\n",
        "\n",
        "    predict_vector=concatenate([mf_vector,mlp_vector])\n",
        "\n",
        "    prediction=Dense(1,activation='sigmoid',kernel_initializer='lecun_uniform',name='prediction')(predict_vector)\n",
        "    model=Model(inputs=[user_input,item_input_pos,item_input_neg,gender_input,age_input,occupation_input],outputs=prediction)\n",
        "\n",
        "    tf.keras.utils.plot_model(\n",
        "      model,\n",
        "      to_file=\"model_all.png\",\n",
        "      show_layer_names=True,\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "def get_aux_model(num_users,num_items,aux_inp,mf_dim=10,layers=[10],reg_layers=[0,0,0,0],reg_mf=0):\n",
        "    num_layer=len(layers)\n",
        "\n",
        "    user_input=Input(shape=(1,),dtype='int32')\n",
        "    item_input_pos=Input(shape=(1,),dtype='int32')\n",
        "    item_input_neg = Input(shape=(1,), dtype='int32')\n",
        "    aux_input=Input(shape=(1,),dtype='int32')\n",
        "\n",
        "    MF_embedding_user=Embedding(input_dim=num_users,output_dim=int(mf_dim),embeddings_initializer='random_normal',\n",
        "                                name='mf_user_embedding',embeddings_regularizer=l2(reg_mf),input_length=1)\n",
        "    MF_embedding_aux_user=Embedding(input_dim=aux_inp,output_dim=int(mf_dim),embeddings_initializer='random_normal',\n",
        "                                    name='mf_aux_embedding',embeddings_regularizer=l2(reg_mf),input_length=1)\n",
        "    MF_embedding_item = Embedding(input_dim=num_items, output_dim=mf_dim, embeddings_initializer='random_normal',\n",
        "                                  name='mf_item_embedding',embeddings_regularizer=l2(reg_mf), input_length=1)\n",
        "    MLP_embedding_user=Embedding(input_dim=num_users,output_dim=layers[0],embeddings_initializer='random_normal',\n",
        "                                 name='mlp_user_embedding', embeddings_regularizer=l2(reg_mf),input_length=1)\n",
        "    MLP_embedding_item = Embedding(input_dim=num_items, output_dim=layers[0], embeddings_initializer='random_normal',\n",
        "                                   name='mlp_item_embedding',embeddings_regularizer=l2(reg_mf), input_length=1)\n",
        "\n",
        "    mf_user_latent=Add()([Flatten()(MF_embedding_user(user_input)), Flatten()(MF_embedding_aux_user(aux_input))])\n",
        "    mf_item_latent_pos=Flatten()(MF_embedding_item(item_input_pos))\n",
        "    mf_item_latent_neg = Flatten()(MF_embedding_item(item_input_neg))\n",
        "\n",
        "\n",
        "    prefer_pos = Multiply()([mf_user_latent, mf_item_latent_pos])\n",
        "    prefer_neg = Multiply()([mf_user_latent, mf_item_latent_neg])\n",
        "    prefer_neg = Lambda(lambda x: x)(prefer_neg)\n",
        "    mf_vector = concatenate([prefer_pos, prefer_neg])\n",
        "\n",
        "\n",
        "    mlp_user_latent=Add()([Flatten()(MF_embedding_user(user_input)), Flatten()(MF_embedding_aux_user(aux_input))])\n",
        "    mlp_item_latent_pos=Flatten()(MLP_embedding_item(item_input_pos))\n",
        "    mlp_item_latent_neg=Flatten()(MLP_embedding_item(item_input_neg))\n",
        "    mlp_item_latent_neg=Lambda(lambda x: x)(mlp_item_latent_neg)\n",
        "    mlp_vector=concatenate([mlp_user_latent,mlp_item_latent_pos,mlp_item_latent_neg])\n",
        "    for idx in range(1,num_layer):\n",
        "        layer=Dense(layers[idx],kernel_regularizer=l2(0.0000),activation='tanh',name=\"layer%d\" %idx)\n",
        "        mlp_vector=layer(mlp_vector)\n",
        "\n",
        "    predict_vector=concatenate([mf_vector,mlp_vector])\n",
        "\n",
        "    prediction=Dense(1,activation='sigmoid',kernel_initializer='lecun_uniform',name='prediction')(predict_vector)\n",
        "    model=Model(inputs=[user_input,item_input_pos,item_input_neg,aux_input],outputs=prediction)\n",
        "\n",
        "    tf.keras.utils.plot_model(\n",
        "      model,\n",
        "      to_file=\"model.png\",\n",
        "      show_layer_names=True,\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "def get_aux_train_instances(train, num_negatives):\n",
        "    user_input,item_pos,item_neg,labels,aux_info = [],[],[],[],[]\n",
        "    num_items= train.shape[1]\n",
        "    for (u, i) in train.keys():\n",
        "        # positive instance\n",
        "        user_input.append(u)\n",
        "        aux_info.append(aux_map[dataset.rUserids[u]])\n",
        "        item_pos.append(i)\n",
        "        j = np.random.randint(num_items)\n",
        "        while (u, j) in train.keys():\n",
        "            j = np.random.randint(num_items)\n",
        "        item_neg.append(j)\n",
        "        labels.append(1)\n",
        "\n",
        "        user_input.append(u)\n",
        "        aux_info.append(aux_map[dataset.rUserids[u]])\n",
        "        item_pos.append(j)\n",
        "        item_neg.append(i)\n",
        "        labels.append(0)\n",
        "\n",
        "        # negative instances\n",
        "\n",
        "        for cnt in range(num_negatives-1):\n",
        "            user_input.append(u)\n",
        "            aux_info.append(aux_map[dataset.rUserids[u]])\n",
        "            j=np.random.randint(num_items)\n",
        "            while (u,j) in train.keys():\n",
        "                j = np.random.randint(num_items)\n",
        "            item_pos.append(j)\n",
        "            item_neg.append(i)\n",
        "            labels.append(0)\n",
        "\n",
        "    # np.random.seed(123)\n",
        "    # np.random.shuffle(user_input)\n",
        "    # np.random.seed(123)\n",
        "    # np.random.shuffle(item_pos)\n",
        "    # np.random.seed(123)\n",
        "    # np.random.shuffle(item_neg)\n",
        "    # np.random.seed(123)\n",
        "    # np.random.shuffle(labels)\n",
        "    return user_input, item_pos,item_neg,labels, aux_info\n",
        "\n",
        "def get_feature_train_instances(train, num_negatives):\n",
        "    user_input,item_pos,item_neg,labels,gender_info,age_info,occupation_info = [],[],[],[],[],[],[]\n",
        "    num_items= train.shape[1]\n",
        "    for (u, i) in train.keys():\n",
        "        # positive instance\n",
        "        user_input.append(u)\n",
        "        user = feature_map[dataset.rUserids[u]]\n",
        "        gender_info.append([user[0]])\n",
        "        age_info.append(user[1])\n",
        "        occupation_info.append(user[2])\n",
        "        item_pos.append(i)\n",
        "        j = np.random.randint(num_items)\n",
        "        while (u, j) in train.keys():\n",
        "            j = np.random.randint(num_items)\n",
        "        item_neg.append(j)\n",
        "        labels.append(1)\n",
        "\n",
        "        user_input.append(u)\n",
        "        gender_info.append([user[0]])\n",
        "        age_info.append(user[1])\n",
        "        occupation_info.append(user[2])\n",
        "        item_pos.append(j)\n",
        "        item_neg.append(i)\n",
        "        labels.append(0)\n",
        "\n",
        "        # negative instances\n",
        "\n",
        "        for cnt in range(num_negatives-1):\n",
        "            user_input.append(u)\n",
        "            gender_info.append([user[0]])\n",
        "            age_info.append(user[1])\n",
        "            occupation_info.append(user[2])\n",
        "            j=np.random.randint(num_items)\n",
        "            while (u,j) in train.keys():\n",
        "                j = np.random.randint(num_items)\n",
        "            item_pos.append(j)\n",
        "            item_neg.append(i)\n",
        "            labels.append(0)\n",
        "    return user_input, item_pos,item_neg,labels, gender_info, age_info, occupation_info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRcI3iZ5BYEA",
        "outputId": "7ff3b31b-1d12-4a2a-ee9a-e5963c6b0322"
      },
      "source": [
        "import pandas as pd\n",
        "count = 0\n",
        "data = []\n",
        "with open(\"./data/users.csv\", \"r\") as f:\n",
        "  for line in f.readlines():\n",
        "    if count == 0:\n",
        "      count += 1\n",
        "      continue\n",
        "    else:\n",
        "      data.append(line.strip().split(\";\"))\n",
        "user_df = pd.DataFrame(data, columns=[\"id\", \"gender\", \"age_group\", \"occupation\", \"zipcode\"])\n",
        "print(user_df.shape)\n",
        "user_df.head()\n",
        "\n",
        "# Encode auxilary information\n",
        "idx = 0\n",
        "info2id = {}\n",
        "age2id = {group:i for i, group in enumerate(sorted(user_df.age_group.unique()))}\n",
        "gender2id = {group:i for i, group in enumerate(sorted(user_df.gender.unique()))}\n",
        "occupation2id = {group:i for i, group in enumerate(sorted(user_df.occupation.unique()))}\n",
        "for i, row in user_df.sort_values([\"gender\", \"age_group\", \"occupation\"]).iterrows():\n",
        "  info = (row['gender'], row['age_group'], row['occupation'])\n",
        "  if info not in info2id:\n",
        "    info2id[info] = idx\n",
        "    idx += 1\n",
        "id2info = {v:k for k, v in info2id.items()}\n",
        "user_df['aux_info'] = user_df.apply(lambda row: info2id[(row['gender'], row['age_group'], row['occupation'])], axis=1)\n",
        "aux_map = {row['id']:row['aux_info'] for i, row in user_df.iterrows()}\n",
        "feature_map = {row['id']:[gender2id[row['gender']], age2id[row['age_group']], occupation2id[row['occupation']]] for i, row in user_df.iterrows()}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6040, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDuTNq8795_4",
        "outputId": "4c0bebe0-b1cd-4b3a-c40a-439c7c1d72c8"
      },
      "source": [
        "num_epochs = 20\n",
        "batch_size = 256\n",
        "mf_dim = 16\n",
        "layers = [64,32,16,8]\n",
        "reg_mf = 0\n",
        "reg_layers = [0,0,0,0]\n",
        "num_negatives = 2\n",
        "# learning_rate = args.lr\n",
        "learner = 'adam'\n",
        "verbose = 1\n",
        "topK = 10\n",
        "evaluation_threads = 1#mp.cpu_count()\n",
        "# print(\"NeuPR arguments: %s \" %(args))\n",
        "\n",
        "num_negatives=2\n",
        "learning_rate = 0.0005\n",
        "\n",
        "k=2 # k=[1,2,3,4,8]\n",
        "layers=[e*k for e in layers]\n",
        "\n",
        "learner='adam'\n",
        "t1 = time()\n",
        "dataset = DataSet()\n",
        "dataset.loadClicks('./data/ml1m.txt', 10, 10)\n",
        "train,validRatings, testRatings, testNegatives = dataset.trainMatrix,dataset.validRatings,dataset.testRatings, dataset.testNegatives\n",
        "num_users, num_items = train.shape\n",
        "print(train.shape)\n",
        "print(\"Load data done [%.1f s]. #user=%d, #item=%d, #train=%d, #test=%d\"\n",
        "      % (time() - t1, num_users, num_items, train.nnz, len(testRatings)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Loading clicks from %s, userMin = %d  itemMin = %d  ./data/ml1m.txt 10 10\n",
            "\n",
            "  First pass: #users = %d, #items = %d, #clicks = %d\n",
            " 6040 3706 1000209\n",
            "  Sorting clicks for each users \n",
            "\n",
            " \"nUsers\": %d,\"nItems\":%d, \"nClicks\":%d\n",
            " 6040 3260 998539\n",
            "(6040, 3260)\n",
            "Load data done [32.5 s]. #user=6040, #item=3260, #train=986459, #test=6040\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsBC06B6_9HR",
        "outputId": "d886b7d4-bb97-45a0-f73c-87d1b1cefb3e"
      },
      "source": [
        "######################################################\n",
        "model = get_feature_model(num_users, num_items, len(gender2id), len(age2id), len(occupation2id), mf_dim, layers, reg_layers, reg_mf)\n",
        "\n",
        "if learner.lower() == \"adagrad\":\n",
        "    model.compile(optimizer=Adagrad(lr=learning_rate), loss='binary_crossentropy')\n",
        "elif learner.lower() == \"rmsprop\":\n",
        "    model.compile(optimizer=RMSprop(lr=learning_rate), loss='binary_crossentropy')\n",
        "elif learner.lower() == \"adam\":\n",
        "    model.compile(optimizer=Adam(lr=learning_rate), loss='binary_crossentropy')\n",
        "else:\n",
        "    model.compile(optimizer=SGD(lr=learning_rate), loss='binary_crossentropy')\n",
        "    print('sgd')\n",
        "\n",
        "(hits, ndcgs) = evaluate_feature_model(model, validRatings, testNegatives, topK, evaluation_threads)\n",
        "hr, ndcg = np.array(hits).mean(), np.array(ndcgs).mean()\n",
        "print('Init: HR = %.4f, NDCG = %.4f' % (hr, ndcg))\n",
        "best_hr, best_ndcg, best_iter = hr, ndcg, -1\n",
        "best_test_hr,best_test_ndcg=-1,-1\n",
        "    # Training model\n",
        "all_loss = []\n",
        "for epoch in range(num_epochs):\n",
        "    t1 = time()\n",
        "    # Generate training instances\n",
        "    user_input, item_input_pos,item_input_neg, labels, gender_info, age_info, occupation_info = get_feature_train_instances(train, num_negatives)\n",
        "\n",
        "    # Training\n",
        "    hist = model.fit([np.array(user_input), np.array(item_input_pos),np.array(item_input_neg),np.array(gender_info),np.array(age_info),np.array(occupation_info)],  # input\n",
        "                      np.array(labels),  # labels\n",
        "                      batch_size=batch_size, epochs=1, verbose=0, shuffle=True)\n",
        "    t2 = time()\n",
        "\n",
        "    # model_out_file = 'Pretrain/%s_NeuPR_%d_%s_%d.h5' % (args.dataset, mf_dim, args.layers, epoch)\n",
        "    # model_out_file = 'Pretrain/%s_NeuPR_%d.h5' % (args.dataset, mf_dim)\n",
        "\n",
        "    if epoch % verbose == 0:\n",
        "        (hits, ndcgs) = evaluate_feature_model(model, validRatings, testNegatives, topK, evaluation_threads)\n",
        "        hits,ndcgs=np.array(hits),np.array(ndcgs)\n",
        "        vhr, vndcg=hits[hits>=0].mean(), ndcgs[ndcgs>=0].mean()\n",
        "        (hits, ndcgs) = evaluate_feature_model(model, testRatings, testNegatives, topK, evaluation_threads)\n",
        "        hits, ndcgs = np.array(hits), np.array(ndcgs)\n",
        "        hr, ndcg, loss = hits[hits>=0].mean(), ndcgs[ndcgs>=0].mean(), hist.history['loss'][0]\n",
        "        all_loss.append(loss)\n",
        "        print('Iteration %d [%.1f s]: [Valid HR = %.4f, NDCG = %.4f, loss=%.6f]\\t[Test HR = %.4f, NDCG = %.4f], [%.1f s]'\n",
        "              % (epoch, t2 - t1, vhr,vndcg,loss,hr,ndcg ,time() - t2))\n",
        "        # print('Iteration %d [%.1f s]: Test HR = %.4f, NDCG = %.4f, loss = %.4f [%.1f s]'\n",
        "        #       % (epoch, t2 - t1, hr, ndcg, loss, time() - t2))\n",
        "        if vhr > best_hr:\n",
        "            best_hr, best_ndcg, best_iter = vhr, vndcg, epoch\n",
        "            best_test_hr,best_test_ndcg=hr,ndcg\n",
        "\n",
        "print(\"End. Best Iteration %d: Test HR = %.4f, NDCG = %.4f. \" % (best_iter, best_test_hr, best_test_ndcg))\n",
        "print('learning_rate: %.5f , num_factor: %d' % (learning_rate, mf_dim))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Init: HR = 0.0945, NDCG = 0.0372\n",
            "Iteration 0 [137.3 s]: [Valid HR = 0.4945, NDCG = 0.2875, loss=0.330889]\t[Test HR = 0.3975, NDCG = 0.2263], [30.8 s]\n",
            "Iteration 1 [134.0 s]: [Valid HR = 0.5495, NDCG = 0.3052, loss=0.258925]\t[Test HR = 0.4669, NDCG = 0.2432], [30.3 s]\n",
            "Iteration 2 [137.4 s]: [Valid HR = 0.5904, NDCG = 0.3247, loss=0.221088]\t[Test HR = 0.5012, NDCG = 0.2509], [30.8 s]\n",
            "Iteration 3 [133.7 s]: [Valid HR = 0.5909, NDCG = 0.3328, loss=0.199092]\t[Test HR = 0.4911, NDCG = 0.2514], [30.4 s]\n",
            "Iteration 4 [132.4 s]: [Valid HR = 0.6157, NDCG = 0.3506, loss=0.186240]\t[Test HR = 0.5245, NDCG = 0.2712], [30.3 s]\n",
            "Iteration 5 [131.1 s]: [Valid HR = 0.6285, NDCG = 0.3604, loss=0.178043]\t[Test HR = 0.5303, NDCG = 0.2821], [30.4 s]\n",
            "Iteration 6 [136.6 s]: [Valid HR = 0.6556, NDCG = 0.3807, loss=0.171926]\t[Test HR = 0.5606, NDCG = 0.3031], [31.0 s]\n",
            "Iteration 7 [136.2 s]: [Valid HR = 0.6442, NDCG = 0.3742, loss=0.167064]\t[Test HR = 0.5541, NDCG = 0.2958], [30.5 s]\n",
            "Iteration 8 [132.5 s]: [Valid HR = 0.6570, NDCG = 0.3811, loss=0.163910]\t[Test HR = 0.5672, NDCG = 0.3051], [30.6 s]\n",
            "Iteration 9 [133.8 s]: [Valid HR = 0.6485, NDCG = 0.3673, loss=0.162293]\t[Test HR = 0.5295, NDCG = 0.2724], [30.6 s]\n",
            "Iteration 10 [131.3 s]: [Valid HR = 0.6435, NDCG = 0.3657, loss=0.158916]\t[Test HR = 0.5414, NDCG = 0.2805], [30.5 s]\n",
            "Iteration 11 [133.4 s]: [Valid HR = 0.6568, NDCG = 0.3787, loss=0.158142]\t[Test HR = 0.5477, NDCG = 0.2905], [31.1 s]\n",
            "Iteration 12 [133.9 s]: [Valid HR = 0.6510, NDCG = 0.3714, loss=0.156721]\t[Test HR = 0.5429, NDCG = 0.2800], [30.4 s]\n",
            "Iteration 13 [134.0 s]: [Valid HR = 0.6611, NDCG = 0.3799, loss=0.155579]\t[Test HR = 0.5603, NDCG = 0.2927], [30.7 s]\n",
            "Iteration 14 [136.6 s]: [Valid HR = 0.6659, NDCG = 0.3855, loss=0.155209]\t[Test HR = 0.5601, NDCG = 0.2960], [30.7 s]\n",
            "Iteration 15 [133.0 s]: [Valid HR = 0.6737, NDCG = 0.3937, loss=0.153978]\t[Test HR = 0.5781, NDCG = 0.3097], [31.0 s]\n",
            "Iteration 16 [134.6 s]: [Valid HR = 0.6634, NDCG = 0.3823, loss=0.152556]\t[Test HR = 0.5652, NDCG = 0.2974], [30.8 s]\n",
            "Iteration 17 [136.3 s]: [Valid HR = 0.6596, NDCG = 0.3810, loss=0.151588]\t[Test HR = 0.5543, NDCG = 0.2877], [30.5 s]\n",
            "Iteration 18 [132.9 s]: [Valid HR = 0.6662, NDCG = 0.3898, loss=0.151602]\t[Test HR = 0.5613, NDCG = 0.2982], [30.1 s]\n",
            "Iteration 19 [136.0 s]: [Valid HR = 0.6682, NDCG = 0.3831, loss=0.150907]\t[Test HR = 0.5513, NDCG = 0.2866], [30.4 s]\n",
            "End. Best Iteration 15: Test HR = 0.5781, NDCG = 0.3097. \n",
            "learning_rate: 0.00050 , num_factor: 16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tvlMumntE1vC",
        "outputId": "a70ebb77-4bde-4722-a006-bb18ecaafd43"
      },
      "source": [
        "import plotly\n",
        "import numpy as np\n",
        "import plotly.graph_objs as go\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def display_pca_scatterplot_3D(inp2id, id2inp, weights, user_input=None, words=None, label=None, color_map=None, topn=5, sample=10):\n",
        "    \n",
        "    \n",
        "    three_dim = PCA(random_state=0).fit_transform(weights)[:,:3]\n",
        "    # For 2D, change the three_dim variable into something like two_dim like the following:\n",
        "    # two_dim = PCA(random_state=0).fit_transform(word_vectors)[:,:2]\n",
        "\n",
        "    data = []\n",
        "    count = 0\n",
        "  \n",
        "    trace = go.Scatter(\n",
        "        x = three_dim[:,0], \n",
        "        y = three_dim[:,1],  \n",
        "        #z = three_dim[:,2],\n",
        "        text = list(inp2id.keys()),\n",
        "        name = \"Age group\",\n",
        "        textposition = \"top center\",\n",
        "        textfont_size = 20,\n",
        "        mode = 'markers+text',\n",
        "        marker = {\n",
        "            'size': 10,\n",
        "            'opacity': 0.8,\n",
        "            'color': 2\n",
        "        }\n",
        "\n",
        "    )\n",
        "            \n",
        "    data.append(trace)\n",
        "    \n",
        "# Configure the layout\n",
        "\n",
        "    layout = go.Layout(\n",
        "        margin = {'l': 0, 'r': 0, 'b': 0, 't': 0},\n",
        "        showlegend=True,\n",
        "        legend=dict(\n",
        "        x=1,\n",
        "        y=0.5,\n",
        "        font=dict(\n",
        "            family=\"Courier New\",\n",
        "            size=25,\n",
        "            color=\"black\"\n",
        "        )),\n",
        "        font = dict(\n",
        "            family = \" Courier New \",\n",
        "            size = 15),\n",
        "        autosize = False,\n",
        "        width = 1000,\n",
        "        height = 1000\n",
        "        )\n",
        "\n",
        "\n",
        "    plot_figure = go.Figure(data = data, layout = layout)\n",
        "    plot_figure.show()\n",
        "    \n",
        "display_pca_scatterplot_3D(age2id, {}, model.layers[8].get_weights()[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"67e7ce65-48ed-496b-8a8a-92ab0e239dc5\" class=\"plotly-graph-div\" style=\"height:1000px; width:1000px;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"67e7ce65-48ed-496b-8a8a-92ab0e239dc5\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '67e7ce65-48ed-496b-8a8a-92ab0e239dc5',\n",
              "                        [{\"marker\": {\"color\": 2, \"opacity\": 0.8, \"size\": 10}, \"mode\": \"markers+text\", \"name\": \"Age group\", \"text\": [\"18-24\", \"25-34\", \"35-44\", \"45-49\", \"50-55\", \"56+\", \"Under18\"], \"textfont\": {\"size\": 20}, \"textposition\": \"top center\", \"type\": \"scatter\", \"x\": [0.48793789744377136, 0.18143300712108612, -0.12686198949813843, -0.2339199185371399, -0.31003764271736145, -0.33236297965049744, 0.33381181955337524], \"y\": [-0.10964182019233704, -0.20251397788524628, -0.06728682667016983, 0.031062066555023193, 0.01820102334022522, 0.023423034697771072, 0.30675649642944336]}],\n",
              "                        {\"autosize\": false, \"font\": {\"family\": \" Courier New \", \"size\": 15}, \"height\": 1000, \"legend\": {\"font\": {\"color\": \"black\", \"family\": \"Courier New\", \"size\": 25}, \"x\": 1, \"y\": 0.5}, \"margin\": {\"b\": 0, \"l\": 0, \"r\": 0, \"t\": 0}, \"showlegend\": true, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"width\": 1000},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('67e7ce65-48ed-496b-8a8a-92ab0e239dc5');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nrmBVhHqOQ06",
        "outputId": "fd365a70-e295-4b88-9d96-3e3c9fec5453"
      },
      "source": [
        "import plotly\n",
        "import numpy as np\n",
        "import plotly.graph_objs as go\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def display_pca_scatterplot_3D(inp2id, id2inp, weights, user_input=None, words=None, label=None, color_map=None, topn=5, sample=10):\n",
        "    \n",
        "    \n",
        "    three_dim = PCA(random_state=0).fit_transform(weights)[:,:3]\n",
        "    # For 2D, change the three_dim variable into something like two_dim like the following:\n",
        "    # two_dim = PCA(random_state=0).fit_transform(word_vectors)[:,:2]\n",
        "\n",
        "    data = []\n",
        "    count = 0\n",
        "  \n",
        "    trace = go.Scatter(\n",
        "        x = three_dim[:,0], \n",
        "        y = three_dim[:,1],  \n",
        "        #z = three_dim[:,2],\n",
        "        text = list(inp2id.keys()),\n",
        "        name = \"Occupation\",\n",
        "        textposition = \"top center\",\n",
        "        textfont_size = 20,\n",
        "        mode = 'markers+text',\n",
        "        marker = {\n",
        "            'size': 10,\n",
        "            'opacity': 0.8,\n",
        "            'color': 2\n",
        "        }\n",
        "\n",
        "    )\n",
        "            \n",
        "    data.append(trace)\n",
        "    \n",
        "# Configure the layout\n",
        "\n",
        "    layout = go.Layout(\n",
        "        margin = {'l': 0, 'r': 0, 'b': 0, 't': 0},\n",
        "        showlegend=True,\n",
        "        legend=dict(\n",
        "        x=1,\n",
        "        y=0.5,\n",
        "        font=dict(\n",
        "            family=\"Courier New\",\n",
        "            size=25,\n",
        "            color=\"black\"\n",
        "        )),\n",
        "        font = dict(\n",
        "            family = \" Courier New \",\n",
        "            size = 15),\n",
        "        autosize = False,\n",
        "        width = 1000,\n",
        "        height = 1000\n",
        "        )\n",
        "\n",
        "\n",
        "    plot_figure = go.Figure(data = data, layout = layout)\n",
        "    plot_figure.show()\n",
        "    \n",
        "display_pca_scatterplot_3D(occupation2id, {}, model.get_layer(\"occupation_embedding\").get_weights()[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"17e322e1-2f60-447c-8562-190ff1722b7b\" class=\"plotly-graph-div\" style=\"height:1000px; width:1000px;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"17e322e1-2f60-447c-8562-190ff1722b7b\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '17e322e1-2f60-447c-8562-190ff1722b7b',\n",
              "                        [{\"marker\": {\"color\": 2, \"opacity\": 0.8, \"size\": 10}, \"mode\": \"markers+text\", \"name\": \"Occupation\", \"text\": [\"K-12student\", \"academic/educator\", \"artist\", \"clerical/admin\", \"college/grad student\", \"customer_service\", \"doctor/health care\", \"executive/managerial\", \"farmer\", \"homemaker\", \"lawyer\", \"other\", \"programmer\", \"retired\", \"sales/marketing\", \"scientist\", \"self-employed\", \"technician/engineer\", \"tradesman/craftsman\", \"unemployed\", \"writer\"], \"textfont\": {\"size\": 20}, \"textposition\": \"top center\", \"type\": \"scatter\", \"x\": [0.03456941619515419, -0.12122833728790283, -0.09013786911964417, 0.04374777525663376, -0.09732543677091599, 0.2599763572216034, 0.015727823600172997, -0.02413974143564701, 0.1275736391544342, 0.006030373275279999, -0.10842882096767426, 0.05472923070192337, -0.08543416112661362, -0.01314412709325552, -0.023589149117469788, -0.13145862519741058, -0.002013441873714328, 0.06105140224099159, 0.278220534324646, -0.07265307754278183, -0.11207382380962372], \"y\": [0.296248197555542, 0.0018973328405991197, -0.08687451481819153, -0.027634654194116592, 0.07583560049533844, -0.07148409634828568, 0.01940690539777279, 0.011692426167428493, -0.2647804915904999, 0.06847592443227768, 0.03197522833943367, 0.013599256984889507, 0.005688723176717758, 0.05984938517212868, 0.013517431914806366, -0.15083177387714386, -0.0005142068257555366, 0.015557030215859413, 0.07034420222043991, -0.06461657583713531, -0.017351310700178146]}],\n",
              "                        {\"autosize\": false, \"font\": {\"family\": \" Courier New \", \"size\": 15}, \"height\": 1000, \"legend\": {\"font\": {\"color\": \"black\", \"family\": \"Courier New\", \"size\": 25}, \"x\": 1, \"y\": 0.5}, \"margin\": {\"b\": 0, \"l\": 0, \"r\": 0, \"t\": 0}, \"showlegend\": true, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"width\": 1000},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('17e322e1-2f60-447c-8562-190ff1722b7b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frMxnhJfe2NT",
        "outputId": "900fa8c6-4580-44e0-ca3b-a290b1639e30"
      },
      "source": [
        "######################################################\n",
        "model = get_aux_model(num_users, num_items, len(info2id), mf_dim, layers, reg_layers, reg_mf)\n",
        "\n",
        "if learner.lower() == \"adagrad\":\n",
        "    model.compile(optimizer=Adagrad(lr=learning_rate), loss='binary_crossentropy')\n",
        "elif learner.lower() == \"rmsprop\":\n",
        "    model.compile(optimizer=RMSprop(lr=learning_rate), loss='binary_crossentropy')\n",
        "elif learner.lower() == \"adam\":\n",
        "    model.compile(optimizer=Adam(lr=learning_rate), loss='binary_crossentropy')\n",
        "else:\n",
        "    model.compile(optimizer=SGD(lr=learning_rate), loss='binary_crossentropy')\n",
        "    print('sgd')\n",
        "\n",
        "(hits, ndcgs) = evaluate_aux_model(model, validRatings, testNegatives, topK, evaluation_threads)\n",
        "hr, ndcg = np.array(hits).mean(), np.array(ndcgs).mean()\n",
        "print('Init: HR = %.4f, NDCG = %.4f' % (hr, ndcg))\n",
        "best_hr, best_ndcg, best_iter = hr, ndcg, -1\n",
        "best_test_hr,best_test_ndcg=-1,-1\n",
        "    # Training model\n",
        "all_loss = []\n",
        "for epoch in range(num_epochs):\n",
        "    t1 = time()\n",
        "    # Generate training instances\n",
        "    user_input, item_input_pos,item_input_neg, labels, aux_info = get_aux_train_instances(train, num_negatives)\n",
        "\n",
        "    # Training\n",
        "    hist = model.fit([np.array(user_input), np.array(item_input_pos),np.array(item_input_neg),np.array(aux_info)],  # input\n",
        "                      np.array(labels),  # labels\n",
        "                      batch_size=batch_size, epochs=1, verbose=0, shuffle=True)\n",
        "    t2 = time()\n",
        "\n",
        "    # model_out_file = 'Pretrain/%s_NeuPR_%d_%s_%d.h5' % (args.dataset, mf_dim, args.layers, epoch)\n",
        "    # model_out_file = 'Pretrain/%s_NeuPR_%d.h5' % (args.dataset, mf_dim)\n",
        "\n",
        "    if epoch % verbose == 0:\n",
        "        (hits, ndcgs) = evaluate_aux_model(model, validRatings, testNegatives, topK, evaluation_threads)\n",
        "        hits,ndcgs=np.array(hits),np.array(ndcgs)\n",
        "        vhr, vndcg=hits[hits>=0].mean(), ndcgs[ndcgs>=0].mean()\n",
        "        (hits, ndcgs) = evaluate_aux_model(model, testRatings, testNegatives, topK, evaluation_threads)\n",
        "        hits, ndcgs = np.array(hits), np.array(ndcgs)\n",
        "        hr, ndcg, loss = hits[hits>=0].mean(), ndcgs[ndcgs>=0].mean(), hist.history['loss'][0]\n",
        "        all_loss.append(loss)\n",
        "        print('Iteration %d [%.1f s]: [Valid HR = %.4f, NDCG = %.4f, loss=%.6f]\\t[Test HR = %.4f, NDCG = %.4f], [%.1f s]'\n",
        "              % (epoch, t2 - t1, vhr,vndcg,loss,hr,ndcg ,time() - t2))\n",
        "        # print('Iteration %d [%.1f s]: Test HR = %.4f, NDCG = %.4f, loss = %.4f [%.1f s]'\n",
        "        #       % (epoch, t2 - t1, hr, ndcg, loss, time() - t2))\n",
        "        if vhr > best_hr:\n",
        "            best_hr, best_ndcg, best_iter = vhr, vndcg, epoch\n",
        "            best_test_hr,best_test_ndcg=hr,ndcg\n",
        "\n",
        "print(\"End. Best Iteration %d: Test HR = %.4f, NDCG = %.4f. \" % (best_iter, best_test_hr, best_test_ndcg))\n",
        "print('learning_rate: %.5f , num_factor: %d' % (learning_rate, mf_dim))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Init: HR = 0.0889, NDCG = 0.0366\n",
            "Iteration 0 [121.8 s]: [Valid HR = 0.5038, NDCG = 0.2874, loss=0.336338]\t[Test HR = 0.4366, NDCG = 0.2383], [27.1 s]\n",
            "Iteration 1 [118.5 s]: [Valid HR = 0.5773, NDCG = 0.3281, loss=0.246448]\t[Test HR = 0.4937, NDCG = 0.2585], [27.6 s]\n",
            "Iteration 2 [119.9 s]: [Valid HR = 0.6144, NDCG = 0.3440, loss=0.205927]\t[Test HR = 0.5159, NDCG = 0.2633], [27.8 s]\n",
            "Iteration 3 [122.2 s]: [Valid HR = 0.6152, NDCG = 0.3458, loss=0.188180]\t[Test HR = 0.5164, NDCG = 0.2649], [28.3 s]\n",
            "Iteration 4 [120.4 s]: [Valid HR = 0.6419, NDCG = 0.3697, loss=0.177398]\t[Test HR = 0.5568, NDCG = 0.2901], [27.8 s]\n",
            "Iteration 5 [122.3 s]: [Valid HR = 0.6488, NDCG = 0.3697, loss=0.171140]\t[Test HR = 0.5556, NDCG = 0.2905], [27.5 s]\n",
            "Iteration 6 [119.9 s]: [Valid HR = 0.6637, NDCG = 0.3870, loss=0.167139]\t[Test HR = 0.5757, NDCG = 0.3072], [26.9 s]\n",
            "Iteration 7 [119.1 s]: [Valid HR = 0.6553, NDCG = 0.3783, loss=0.163356]\t[Test HR = 0.5689, NDCG = 0.3006], [27.2 s]\n",
            "Iteration 8 [120.4 s]: [Valid HR = 0.6710, NDCG = 0.3934, loss=0.161148]\t[Test HR = 0.5846, NDCG = 0.3204], [27.0 s]\n",
            "Iteration 9 [119.2 s]: [Valid HR = 0.6551, NDCG = 0.3737, loss=0.160090]\t[Test HR = 0.5470, NDCG = 0.2799], [26.6 s]\n",
            "Iteration 10 [117.7 s]: [Valid HR = 0.6555, NDCG = 0.3768, loss=0.157370]\t[Test HR = 0.5540, NDCG = 0.2886], [27.0 s]\n",
            "Iteration 11 [116.5 s]: [Valid HR = 0.6687, NDCG = 0.3893, loss=0.156855]\t[Test HR = 0.5545, NDCG = 0.2946], [27.2 s]\n",
            "Iteration 12 [119.3 s]: [Valid HR = 0.6581, NDCG = 0.3788, loss=0.155633]\t[Test HR = 0.5440, NDCG = 0.2819], [27.4 s]\n",
            "Iteration 13 [119.4 s]: [Valid HR = 0.6687, NDCG = 0.3874, loss=0.154811]\t[Test HR = 0.5644, NDCG = 0.2952], [27.5 s]\n",
            "Iteration 14 [121.0 s]: [Valid HR = 0.6796, NDCG = 0.3927, loss=0.154623]\t[Test HR = 0.5646, NDCG = 0.2987], [27.5 s]\n",
            "Iteration 15 [120.9 s]: [Valid HR = 0.6773, NDCG = 0.3968, loss=0.153422]\t[Test HR = 0.5767, NDCG = 0.3083], [28.1 s]\n",
            "Iteration 16 [115.0 s]: [Valid HR = 0.6685, NDCG = 0.3886, loss=0.152373]\t[Test HR = 0.5608, NDCG = 0.2955], [26.8 s]\n",
            "Iteration 17 [117.1 s]: [Valid HR = 0.6667, NDCG = 0.3833, loss=0.151615]\t[Test HR = 0.5520, NDCG = 0.2854], [28.1 s]\n",
            "Iteration 18 [119.6 s]: [Valid HR = 0.6748, NDCG = 0.3936, loss=0.151417]\t[Test HR = 0.5626, NDCG = 0.3023], [27.3 s]\n",
            "Iteration 19 [121.3 s]: [Valid HR = 0.6710, NDCG = 0.3847, loss=0.151105]\t[Test HR = 0.5573, NDCG = 0.2916], [27.9 s]\n",
            "End. Best Iteration 14: Test HR = 0.5646, NDCG = 0.2987. \n",
            "learning_rate: 0.00050 , num_factor: 16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Zb68rBWoesy4",
        "outputId": "9f537999-eabd-4f91-d48e-16c46f2b7bb1"
      },
      "source": [
        "num_epochs = 20\n",
        "batch_size = 256\n",
        "mf_dim = 16\n",
        "layers = [32,32,16,8]\n",
        "reg_mf = 0\n",
        "reg_layers = [0,0,0,0]\n",
        "num_negatives = 2\n",
        "# learning_rate = args.lr\n",
        "learner = 'adam'\n",
        "verbose = 1\n",
        "topK = 10\n",
        "evaluation_threads = 1#mp.cpu_count()\n",
        "# print(\"NeuPR arguments: %s \" %(args))\n",
        "\n",
        "num_negatives=2\n",
        "learning_rate = 0.0005\n",
        "\n",
        "k=2 # k=[1,2,3,4,8]\n",
        "layers=[e*k for e in layers]\n",
        "\n",
        "learner='adam'\n",
        "t1 = time()\n",
        "dataset = DataSet()\n",
        "dataset.loadClicks('./data/ml1m.txt', 10, 10)\n",
        "train,validRatings, testRatings, testNegatives = dataset.trainMatrix,dataset.validRatings,dataset.testRatings, dataset.testNegatives\n",
        "num_users, num_items = train.shape\n",
        "print(train.shape)\n",
        "print(\"Load data done [%.1f s]. #user=%d, #item=%d, #train=%d, #test=%d\"\n",
        "      % (time() - t1, num_users, num_items, train.nnz, len(testRatings)))\n",
        "\n",
        "######################################################\n",
        "model = get_model(num_users, num_items, mf_dim, layers, reg_layers, reg_mf)\n",
        "\n",
        "if learner.lower() == \"adagrad\":\n",
        "    model.compile(optimizer=Adagrad(lr=learning_rate), loss='binary_crossentropy')\n",
        "elif learner.lower() == \"rmsprop\":\n",
        "    model.compile(optimizer=RMSprop(lr=learning_rate), loss='binary_crossentropy')\n",
        "elif learner.lower() == \"adam\":\n",
        "    model.compile(optimizer=Adam(lr=learning_rate), loss='binary_crossentropy')\n",
        "else:\n",
        "    model.compile(optimizer=SGD(lr=learning_rate), loss='binary_crossentropy')\n",
        "    print('sgd')\n",
        "\n",
        "(hits, ndcgs) = evaluate_model(model, validRatings, testNegatives, topK, evaluation_threads)\n",
        "hr, ndcg = np.array(hits).mean(), np.array(ndcgs).mean()\n",
        "print('Init: HR = %.4f, NDCG = %.4f' % (hr, ndcg))\n",
        "best_hr, best_ndcg, best_iter = hr, ndcg, -1\n",
        "best_test_hr,best_test_ndcg=-1,-1\n",
        "    # Training model\n",
        "all_loss = []\n",
        "for epoch in range(num_epochs):\n",
        "    t1 = time()\n",
        "    # Generate training instances\n",
        "    user_input, item_input_pos,item_input_neg, labels = get_train_instances(train, num_negatives)\n",
        "\n",
        "    # Training\n",
        "    hist = model.fit([np.array(user_input), np.array(item_input_pos),np.array(item_input_neg)],  # input\n",
        "                      np.array(labels),  # labels\n",
        "                      batch_size=batch_size, epochs=1, verbose=0, shuffle=True)\n",
        "    t2 = time()\n",
        "\n",
        "    # model_out_file = 'Pretrain/%s_NeuPR_%d_%s_%d.h5' % (args.dataset, mf_dim, args.layers, epoch)\n",
        "    # model_out_file = 'Pretrain/%s_NeuPR_%d.h5' % (args.dataset, mf_dim)\n",
        "\n",
        "    if epoch % verbose == 0:\n",
        "        (hits, ndcgs) = evaluate_model(model, validRatings, testNegatives, topK, evaluation_threads)\n",
        "        hits,ndcgs=np.array(hits),np.array(ndcgs)\n",
        "        vhr, vndcg=hits[hits>=0].mean(), ndcgs[ndcgs>=0].mean()\n",
        "        (hits, ndcgs) = evaluate_model(model, testRatings, testNegatives, topK, evaluation_threads)\n",
        "        hits, ndcgs = np.array(hits), np.array(ndcgs)\n",
        "        hr, ndcg, loss = hits[hits>=0].mean(), ndcgs[ndcgs>=0].mean(), hist.history['loss'][0]\n",
        "        all_loss.append(loss)\n",
        "        print('Iteration %d [%.1f s]: [Valid HR = %.4f, NDCG = %.4f, loss=%.6f]\\t[Test HR = %.4f, NDCG = %.4f], [%.1f s]'\n",
        "              % (epoch, t2 - t1, vhr,vndcg,loss,hr,ndcg ,time() - t2))\n",
        "        # print('Iteration %d [%.1f s]: Test HR = %.4f, NDCG = %.4f, loss = %.4f [%.1f s]'\n",
        "        #       % (epoch, t2 - t1, hr, ndcg, loss, time() - t2))\n",
        "        if vhr > best_hr:\n",
        "            best_hr, best_ndcg, best_iter = vhr, vndcg, epoch\n",
        "            best_test_hr,best_test_ndcg=hr,ndcg\n",
        "\n",
        "print(\"End. Best Iteration %d: Test HR = %.4f, NDCG = %.4f. \" % (best_iter, best_test_hr, best_test_ndcg))\n",
        "print('learning_rate: %.5f , num_factor: %d' % (learning_rate, mf_dim))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Loading clicks from %s, userMin = %d  itemMin = %d  ./data/ml1m.txt 10 10\n",
            "\n",
            "  First pass: #users = %d, #items = %d, #clicks = %d\n",
            " 6040 3706 1000209\n",
            "  Sorting clicks for each users \n",
            "\n",
            " \"nUsers\": %d,\"nItems\":%d, \"nClicks\":%d\n",
            " 6040 3260 998539\n",
            "(6040, 3260)\n",
            "Load data done [31.8 s]. #user=6040, #item=3260, #train=986459, #test=6040\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Init: HR = 0.1358, NDCG = 0.0679\n",
            "Iteration 0 [98.1 s]: [Valid HR = 0.5407, NDCG = 0.3090, loss=0.320730]\t[Test HR = 0.4699, NDCG = 0.2552], [19.6 s]\n",
            "Iteration 1 [96.9 s]: [Valid HR = 0.6070, NDCG = 0.3493, loss=0.219318]\t[Test HR = 0.5167, NDCG = 0.2753], [19.6 s]\n",
            "Iteration 2 [97.3 s]: [Valid HR = 0.6364, NDCG = 0.3596, loss=0.190550]\t[Test HR = 0.5437, NDCG = 0.2785], [19.8 s]\n",
            "Iteration 3 [97.1 s]: [Valid HR = 0.6353, NDCG = 0.3636, loss=0.176989]\t[Test HR = 0.5416, NDCG = 0.2816], [20.1 s]\n",
            "Iteration 4 [97.7 s]: [Valid HR = 0.6518, NDCG = 0.3799, loss=0.168104]\t[Test HR = 0.5614, NDCG = 0.2974], [19.9 s]\n",
            "Iteration 5 [97.4 s]: [Valid HR = 0.6611, NDCG = 0.3849, loss=0.162975]\t[Test HR = 0.5667, NDCG = 0.3014], [20.0 s]\n",
            "Iteration 6 [97.1 s]: [Valid HR = 0.6727, NDCG = 0.3958, loss=0.159218]\t[Test HR = 0.5935, NDCG = 0.3170], [19.8 s]\n",
            "Iteration 7 [97.9 s]: [Valid HR = 0.6661, NDCG = 0.3911, loss=0.155770]\t[Test HR = 0.5778, NDCG = 0.3118], [19.4 s]\n",
            "Iteration 8 [96.0 s]: [Valid HR = 0.6790, NDCG = 0.4003, loss=0.153832]\t[Test HR = 0.5960, NDCG = 0.3243], [19.6 s]\n",
            "Iteration 9 [94.2 s]: [Valid HR = 0.6705, NDCG = 0.3893, loss=0.152874]\t[Test HR = 0.5568, NDCG = 0.2906], [19.5 s]\n",
            "Iteration 10 [94.5 s]: [Valid HR = 0.6639, NDCG = 0.3896, loss=0.149595]\t[Test HR = 0.5659, NDCG = 0.2988], [19.4 s]\n",
            "Iteration 11 [94.8 s]: [Valid HR = 0.6733, NDCG = 0.3947, loss=0.149211]\t[Test HR = 0.5593, NDCG = 0.2973], [19.3 s]\n",
            "Iteration 12 [95.2 s]: [Valid HR = 0.6629, NDCG = 0.3853, loss=0.147645]\t[Test HR = 0.5434, NDCG = 0.2858], [19.2 s]\n",
            "Iteration 13 [93.9 s]: [Valid HR = 0.6727, NDCG = 0.3927, loss=0.146248]\t[Test HR = 0.5604, NDCG = 0.2949], [19.5 s]\n",
            "Iteration 14 [95.4 s]: [Valid HR = 0.6820, NDCG = 0.4004, loss=0.145464]\t[Test HR = 0.5656, NDCG = 0.3007], [19.7 s]\n",
            "Iteration 15 [94.7 s]: [Valid HR = 0.6816, NDCG = 0.4015, loss=0.143956]\t[Test HR = 0.5732, NDCG = 0.3073], [19.2 s]\n",
            "Iteration 16 [94.3 s]: [Valid HR = 0.6699, NDCG = 0.3930, loss=0.142595]\t[Test HR = 0.5555, NDCG = 0.2947], [19.2 s]\n",
            "Iteration 17 [94.0 s]: [Valid HR = 0.6715, NDCG = 0.3903, loss=0.141883]\t[Test HR = 0.5469, NDCG = 0.2874], [19.0 s]\n",
            "Iteration 18 [93.1 s]: [Valid HR = 0.6737, NDCG = 0.3972, loss=0.141100]\t[Test HR = 0.5662, NDCG = 0.3035], [19.6 s]\n",
            "Iteration 19 [95.5 s]: [Valid HR = 0.6641, NDCG = 0.3838, loss=0.140718]\t[Test HR = 0.5459, NDCG = 0.2865], [19.0 s]\n",
            "Iteration 20 [93.1 s]: [Valid HR = 0.6724, NDCG = 0.3955, loss=0.139476]\t[Test HR = 0.5609, NDCG = 0.2977], [18.6 s]\n",
            "Iteration 21 [94.8 s]: [Valid HR = 0.6770, NDCG = 0.3975, loss=0.139255]\t[Test HR = 0.5432, NDCG = 0.2890], [19.1 s]\n",
            "Iteration 22 [94.5 s]: [Valid HR = 0.6672, NDCG = 0.3904, loss=0.138455]\t[Test HR = 0.5533, NDCG = 0.2924], [19.1 s]\n",
            "Iteration 23 [93.5 s]: [Valid HR = 0.6780, NDCG = 0.4012, loss=0.138149]\t[Test HR = 0.5566, NDCG = 0.2958], [19.3 s]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-342e563fcc0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m     hist = model.fit([np.array(user_input), np.array(item_input_pos),np.array(item_input_neg)],  # input\n\u001b[1;32m     59\u001b[0m                       \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                       batch_size=batch_size, epochs=1, verbose=0, shuffle=True)\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "2lEKe3iCgWOD",
        "outputId": "879e34cc-e0e9-4499-f4db-b90a218ff0e4"
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.2.4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyP-QdxbgkL1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}